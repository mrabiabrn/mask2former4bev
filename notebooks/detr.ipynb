{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b45eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c512e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/mbarin22/.conda/envs/mask2former/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../simplebev_org/simple_bev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d716fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = torch.load('/kuacc/users/mbarin22/hpc_run/mask2former4bev/scripts/train_features1.pt')['features']\n",
    "val_feats = torch.load('/kuacc/users/mbarin22/hpc_run/mask2former4bev/scripts/val_features0.pt')['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1a286b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 128, 56, 100]), torch.Size([6, 128, 56, 100]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.shape , val_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eb8663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1790, -0.1809, -0.6387,  ..., -0.4426, -0.4675,  0.0377],\n",
       "         [-0.4902, -0.6079, -0.1766,  ..., -0.5630, -0.3174, -0.5464],\n",
       "         [-0.9395, -0.2546, -0.3564,  ...,  0.3987,  0.1320, -0.3613],\n",
       "         ...,\n",
       "         [-0.1486, -0.8853, -0.3152,  ..., -0.8730, -0.5542, -0.1842],\n",
       "         [-0.7324, -0.2751,  0.1979,  ..., -1.1748, -0.5381, -0.2935],\n",
       "         [-0.4658, -0.6895, -0.4309,  ..., -0.9487, -0.3013, -0.2239]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>),\n",
       " tensor([[-0.1801,  0.0553, -0.4524,  ..., -0.1664, -0.1512,  0.1095],\n",
       "         [-0.2925,  0.0085, -0.4529,  ..., -0.6133, -0.2236, -0.5327],\n",
       "         [-0.3406, -0.1810, -0.4399,  ..., -0.4402, -0.1650,  0.2208],\n",
       "         ...,\n",
       "         [-0.3569, -0.9351, -0.5054,  ..., -0.2930,  0.2839, -0.0400],\n",
       "         [ 0.0018, -0.1142, -0.4016,  ..., -0.2330, -0.2054, -0.4307],\n",
       "         [-0.3655, -1.3965, -0.6377,  ..., -0.7739, -0.3372, -0.3994]],\n",
       "        device='cuda:0', dtype=torch.float16))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats[5][0], val_feats[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5531d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        self.is_loss_weights_param = 0\n",
    "        self.project = 'mask2former4bev'\n",
    "        self.model_name = 'detr4bev'\n",
    "        self.dataset_path = '/datasets/nuscenes'\n",
    "        self.version = 'trainval'\n",
    "\n",
    "        # write all the parameters like above\n",
    "        self.res_scale = 1\n",
    "        self.H = 1600\n",
    "        self.W = 900\n",
    "        self.rand_crop_and_resize = 0\n",
    "        \n",
    "        self.resize_to = [448,800]\n",
    "        self.crop_offset = 0\n",
    "        self.random_flip = 0\n",
    "        self.resize_lim = [1.0, 1.0]\n",
    "        self.cams = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n",
    "        self.ncams = 6\n",
    "\n",
    "        self.do_shuffle_cams = 0\n",
    "        self.refcam_id = 1\n",
    "\n",
    "        self.backbone = \"res101-simplebev\"\n",
    "        self.freeze_backbone = 0\n",
    "        self.patch_size = 16\n",
    "\n",
    "        self.mask_classification = 1\n",
    "        self.class_weight = 1.0\n",
    "        self.dice_weight = 1.0\n",
    "        self.mask_weight = 20.0\n",
    "        self.no_object_weight = 0.1\n",
    "        self.deep_supervision = 1\n",
    "\n",
    "        self.train_num_points = 112*112\n",
    "        self.oversample_ratio = 3.0\n",
    "        self.importance_sample_ratio = 0.75\n",
    "\n",
    "        self.sem_seg_head_name = 'detr_head'\n",
    "        self.transformer_in_feature = 'multi_scale_bev_features'\n",
    "\n",
    "        self.bev_module_name = 'SimpleBEV'\n",
    "        self.bev_latent_dim = 128\n",
    "        self.multiscale_feature_channels = [64, 128, 256]\n",
    "        self.multiscale_feature_norm = 'batch'\n",
    "        self.multiscale_conv_dim = 256\n",
    "        self.voxel_size = [200, 8, 200]\n",
    "        self.bounds = [-50, 50, -5, 5, -50, 50]\n",
    "        self.do_rgb_compress = 1\n",
    "\n",
    "        self.use_frozen_bev_feats = 0\n",
    "        self.frozen_bev_feats_path = '/kuacc/users/mbarin22/hpc_run/mask2former4bev/checkpoints/simplebev/8x5_5e-4_rgb12_22:43:46/model-000025000.pth'\n",
    "\n",
    "        self.num_classes = 1\n",
    "\n",
    "        self.predictor_type = 'TransformerPredictor'\n",
    "        self.nheads = 8\n",
    "        self.dec_layers = 6\n",
    "        self.pe_hidden_dim = 256\n",
    "        self.predictor_dropout = 0\n",
    "        self.num_queries = 50\n",
    "        self.pre_norm = 0\n",
    "        self.dim_feedforward = 2048\n",
    "        self.enforce_input_project = 0\n",
    "        self.mask_dim = 256\n",
    "        \n",
    "        self.use_multiscale_features = 1\n",
    "        self.rt_regression = 0\n",
    "        self.translation_weight =1\n",
    "        self.heading_weight = 1\n",
    "\n",
    "        self.use_lidar = 1\n",
    "\n",
    "        self.decoder_type = 'conv'\n",
    "\n",
    "        self.learning_rate = 4e-4\n",
    "        self.weight_decay = 1e-7\n",
    "        self.dropout = 0.0\n",
    "        \n",
    "        self.validate_with_gt = False\n",
    "\n",
    "\n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645872fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/kuacc/users/mbarin22/hpc_run/mask2former4bev/checkpoints/detr_[448, 800]_bs:1_nq:50_10k_0.0001_overfit/epoch_2800.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be15678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NuScenes version trainval from /datasets/nuscenes\n",
      "Done loading NuScenes version trainval\n"
     ]
    }
   ],
   "source": [
    "from dataset import NuScenesDatasetWrapper\n",
    "\n",
    "datamodule = NuScenesDatasetWrapper(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eeea26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, in_channels: 64\n",
      "idx: 1, in_channels: 128\n",
      "idx: 2, in_channels: 256\n",
      "lateral_convs 0: None\n",
      "lateral_convs 1: Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "lateral_convs 2: Sequential(\n",
      "  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "output_convs 0: Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "output_convs 1: Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "output_convs 2: Sequential(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DETR4BEV(\n",
       "  (backbone): SimpleBEVEncoder(\n",
       "    (encoder): Encoder_res101(\n",
       "      (backbone): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (depth_layer): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (upsampling_layer): UpsamplingConcat(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (sem_seg_head): DETRHead(\n",
       "    (pixel_decoder): SimpleBEVModule(\n",
       "      (adapter_1): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (layer_1): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (adapter_2): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (layer_2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (layer_3): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (segnet): Segnet(\n",
       "        (bev_compressor): Sequential(\n",
       "          (0): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (decoder): BEVDecoder(\n",
       "          (first_conv): Conv2d(128, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (layer1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (up3_skip): UpsamplingAdd(\n",
       "            (upsample_layer): Sequential(\n",
       "              (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "              (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            )\n",
       "          )\n",
       "          (up2_skip): UpsamplingAdd(\n",
       "            (upsample_layer): Sequential(\n",
       "              (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "              (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            )\n",
       "          )\n",
       "          (up1_skip): UpsamplingAdd(\n",
       "            (upsample_layer): Sequential(\n",
       "              (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "              (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            )\n",
       "          )\n",
       "          (feat_head): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (segmentation_head): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (instance_offset_head): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (instance_center_head): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mask_features): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (predictor): DETRTransformer(\n",
       "      (pe_layer): PositionEmbeddingSine()\n",
       "      (transformer): Transformer(\n",
       "        (encoder): TransformerEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): TransformerEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): TransformerEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): TransformerEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (3): TransformerEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (4): TransformerEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (5): TransformerEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (decoder): TransformerDecoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (3): TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (4): TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (5): TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (class_embed): Linear(in_features=256, out_features=2, bias=True)\n",
       "      (bbox_embed): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (query_embed): Embedding(50, 256)\n",
       "      (input_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): Criterion SetCriterion\n",
       "      matcher: HungarianMatcherDETR()\n",
       "      losses: ['labels', 'boxes', 'cardinality']\n",
       "      weight_dict: {'loss_ce': 1, 'loss_bbox': 5, 'loss_giou': 2, 'loss_ce_0': 1, 'loss_bbox_0': 5, 'loss_giou_0': 2, 'loss_ce_1': 1, 'loss_bbox_1': 5, 'loss_giou_1': 2, 'loss_ce_2': 1, 'loss_bbox_2': 5, 'loss_giou_2': 2, 'loss_ce_3': 1, 'loss_bbox_3': 5, 'loss_giou_3': 2, 'loss_ce_4': 1, 'loss_bbox_4': 5, 'loss_giou_4': 2}\n",
       "      num_classes: 1\n",
       "      eos_coef: 0.1\n",
       "      num_points: 12544\n",
       "      oversample_ratio: 3.0\n",
       "      importance_sample_ratio: 0.75\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.mask2former4bev import DETR4BEV\n",
    "\n",
    "model = DETR4BEV(args).cuda()\n",
    "loaded_model = OrderedDict((key.replace('module.', ''), value) for key, value in torch.load(ckpt_path)[\"model\"].items()) \n",
    "\n",
    "model.load_state_dict(loaded_model,strict=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e426bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_train False\n",
      "is_train True\n"
     ]
    }
   ],
   "source": [
    "valset = datamodule.val()\n",
    "trainset = datamodule.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba7cc8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_logits tensor([[[0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861],\n",
      "         [0.7139, 0.2861]]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "pred_boxes tensor([[[0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791],\n",
      "         [0.5273, 0.5069, 0.0549, 0.0791]]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "AIAIAIAIAI\n",
      "device  cuda:0\n",
      "heyyeyeyey\n",
      "in the forward function of criterion\n",
      "indices:  [(tensor([ 5,  8,  9, 10, 13, 21, 23, 27, 30, 44, 48, 49]), tensor([ 1,  6,  8,  7,  2,  9,  5, 10,  3,  0,  4, 11]))]\n"
     ]
    }
   ],
   "source": [
    "idx = 12485\n",
    "batch = trainset[idx] #valset[idx]\n",
    "preds = model([batch]) #, training=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f59572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'rots', 'trans', 'intrins', 'seg_bev', 'valid_bev', 'center_bev', 'offset_bev', 'ego_pose', 'multi_seg_bev', 'gt_masks', 'multi_valid_bev', 'gt_valid', 'translation_rotation_list'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93136157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0ba1329790>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch['gt_masks'][0]*batch['gt_valid'][0], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75bd08da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f53a56de160>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAis0lEQVR4nO3de3BU9f3/8deGkAU02ZhAslkNEFBBC6SIss3UUpAoBAdBUysYK1YELwGVaKXpVBGm01Bp1VGp1hkBO+J1hsuI39LhFiI1RAhmGG8ZwkQQSUKFyS4JsiTk8/vDH6fdJgECWfaT+HzMnBn2nM8e3jlkeLq7h+gyxhgBAGChmGgPAABAe4gUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaUYvU0qVLNXDgQPXq1Ut+v18ff/xxtEYBAFgqKpF65513VFBQoAULFmjXrl3KzMzUhAkTdOjQoWiMAwCwlCsaP2DW7/fruuuu00svvSRJamlpUXp6uubOnavf/va3Z3x+S0uLDh48qPj4eLlcrkiPCwDoZMYYHT16VD6fTzEx7b9eir2AM0mSTpw4ofLychUWFjr7YmJilJ2drdLS0jafEwqFFAqFnMfffPONrr766ojPCgCIrK+//lqXXXZZu8cveKS+/fZbnTx5UqmpqWH7U1NT9eWXX7b5nKKiIi1cuLDV/us1SbHqGZE5AQCR06wmbdP/KT4+/rTrLnikzkVhYaEKCgqcx8FgUOnp6YpVT8W6iBQAdDn//4OmM31kc8Ej1bdvX/Xo0UN1dXVh++vq6uT1ett8jtvtltvtvhDjAQAscsHv7ouLi9OoUaO0adMmZ19LS4s2bdqkrKysCz0OAMBiUXm7r6CgQDNmzNC1116r0aNH6/nnn1djY6N+/etfR2McAIClohKpO+64Q//+97/11FNPqba2Vj/+8Y+1fv36VjdTAAB+2KLy76TOVzAYlMfj0VhN4cYJAOiCmk2TirVWgUBACQkJ7a7jZ/cBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrdXqkioqKdN111yk+Pl4pKSmaOnWqKisrw9aMHTtWLpcrbHvggQc6exQAQBfX6ZHaunWr8vPztX37dm3YsEFNTU266aab1NjYGLZu1qxZqqmpcbZnnnmms0cBAHRxsZ19wvXr14c9XrFihVJSUlReXq4xY8Y4+/v06SOv19vZvz0AoBuJ+GdSgUBAkpSUlBS2f+XKlerbt6+GDRumwsJCHTt2rN1zhEIhBYPBsA0A0P11+iup/9bS0qJHH31UP/3pTzVs2DBn/5133qkBAwbI5/Np9+7dmj9/viorK7Vq1ao2z1NUVKSFCxdGclQAgIVcxhgTqZM/+OCD+sc//qFt27bpsssua3fd5s2bNX78eFVVVWnw4MGtjodCIYVCIedxMBhUenq6xmqKYl09IzI7ACBymk2TirVWgUBACQkJ7a6L2CupOXPmaN26dSopKTltoCTJ7/dLUruRcrvdcrvdEZkTAGCvTo+UMUZz587V6tWrVVxcrIyMjDM+p6KiQpKUlpbW2eMAALqwTo9Ufn6+3nzzTa1du1bx8fGqra2VJHk8HvXu3Vt79+7Vm2++qUmTJik5OVm7d+/WvHnzNGbMGI0YMaKzxwEAdGGd/pmUy+Vqc//y5ct1zz336Ouvv9Zdd92lTz/9VI2NjUpPT9ett96q3//+96d9X/K/BYNBeTwePpMCgC4qap9Jnal56enp2rp1a2f/tgCAboif3QcAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKzV6ZF6+umn5XK5wrahQ4c6x48fP678/HwlJyfr4osvVm5ururq6jp7DABANxCRV1I/+tGPVFNT42zbtm1zjs2bN0/vv/++3nvvPW3dulUHDx7UbbfdFokxAABdXGxEThobK6/X22p/IBDQa6+9pjfffFM33HCDJGn58uW66qqrtH37dv3kJz+JxDgAgC4qIq+k9uzZI5/Pp0GDBikvL0/79++XJJWXl6upqUnZ2dnO2qFDh6p///4qLS1t93yhUEjBYDBsAwB0f50eKb/frxUrVmj9+vV6+eWXVV1drZ/97Gc6evSoamtrFRcXp8TExLDnpKamqra2tt1zFhUVyePxOFt6enpnjw0AsFCnv92Xk5Pj/HrEiBHy+/0aMGCA3n33XfXu3fuczllYWKiCggLncTAYJFQA8AMQ8VvQExMTdeWVV6qqqkper1cnTpxQfX192Jq6uro2P8M6xe12KyEhIWwDAHR/EY9UQ0OD9u7dq7S0NI0aNUo9e/bUpk2bnOOVlZXav3+/srKyIj0KAKCL6fS3+x5//HFNnjxZAwYM0MGDB7VgwQL16NFD06dPl8fj0cyZM1VQUKCkpCQlJCRo7ty5ysrK4s4+AEArnR6pAwcOaPr06Tp8+LD69eun66+/Xtu3b1e/fv0kSc8995xiYmKUm5urUCikCRMm6K9//WtnjwEA6AZcxhgT7SE6KhgMyuPxaKymKNbVM9rjAAA6qNk0qVhrFQgETnufAT+7DwBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCs1emRGjhwoFwuV6stPz9fkjR27NhWxx544IHOHgMA0A3EdvYJd+zYoZMnTzqPP/30U9144426/fbbnX2zZs3SokWLnMd9+vTp7DEAAN1Ap0eqX79+YY8XL16swYMH6+c//7mzr0+fPvJ6vWd9zlAopFAo5DwOBoPnPygAwHoR/UzqxIkTeuONN3TvvffK5XI5+1euXKm+fftq2LBhKiws1LFjx057nqKiInk8HmdLT0+P5NgAAEu4jDEmUid/9913deedd2r//v3y+XySpFdffVUDBgyQz+fT7t27NX/+fI0ePVqrVq1q9zxtvZJKT0/XWE1RrKtnpMYHAERIs2lSsdYqEAgoISGh3XURjdSECRMUFxen999/v901mzdv1vjx41VVVaXBgwef1XmDwaA8Hg+RAoAu6mwjFbG3+/bt26eNGzfqvvvuO+06v98vSaqqqorUKACALipikVq+fLlSUlJ08803n3ZdRUWFJCktLS1SowAAuqhOv7tPklpaWrR8+XLNmDFDsbH/+S327t2rN998U5MmTVJycrJ2796tefPmacyYMRoxYkQkRgEAdGERidTGjRu1f/9+3XvvvWH74+LitHHjRj3//PNqbGxUenq6cnNz9fvf/z4SYwAAuriI3jgRKdw4AQBdW9RvnAAA4HwRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaHY5USUmJJk+eLJ/PJ5fLpTVr1oQdN8boqaeeUlpamnr37q3s7Gzt2bMnbM2RI0eUl5enhIQEJSYmaubMmWpoaDivLwQA0P10OFKNjY3KzMzU0qVL2zz+zDPP6IUXXtArr7yisrIyXXTRRZowYYKOHz/urMnLy9Nnn32mDRs2aN26dSopKdHs2bPP/asAAHRLLmOMOecnu1xavXq1pk6dKun7V1E+n0+PPfaYHn/8cUlSIBBQamqqVqxYoWnTpumLL77Q1VdfrR07dujaa6+VJK1fv16TJk3SgQMH5PP5Wv0+oVBIoVDIeRwMBpWenq6xmqJYV89zHR8AECXNpknFWqtAIKCEhIR213XqZ1LV1dWqra1Vdna2s8/j8cjv96u0tFSSVFpaqsTERCdQkpSdna2YmBiVlZW1ed6ioiJ5PB5nS09P78yxAQCW6tRI1dbWSpJSU1PD9qempjrHamtrlZKSEnY8NjZWSUlJzpr/VVhYqEAg4Gxff/11Z44NALBUbLQHOBtut1tutzvaYwAALrBOfSXl9XolSXV1dWH76+rqnGNer1eHDh0KO97c3KwjR444awAAkDo5UhkZGfJ6vdq0aZOzLxgMqqysTFlZWZKkrKws1dfXq7y83FmzefNmtbS0yO/3d+Y4AIAursNv9zU0NKiqqsp5XF1drYqKCiUlJal///569NFH9Yc//EFXXHGFMjIy9OSTT8rn8zl3AF511VWaOHGiZs2apVdeeUVNTU2aM2eOpk2b1uadfQCAH64OR2rnzp0aN26c87igoECSNGPGDK1YsUJPPPGEGhsbNXv2bNXX1+v666/X+vXr1atXL+c5K1eu1Jw5czR+/HjFxMQoNzdXL7zwQid8OQCA7uS8/p1UtASDQXk8Hv6dFAB0UVH5d1IAAHQmIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYq8ORKikp0eTJk+Xz+eRyubRmzRrnWFNTk+bPn6/hw4froosuks/n0913362DBw+GnWPgwIFyuVxh2+LFi8/7iwEAdC8djlRjY6MyMzO1dOnSVseOHTumXbt26cknn9SuXbu0atUqVVZW6pZbbmm1dtGiRaqpqXG2uXPnnttXAADotmI7+oScnBzl5OS0eczj8WjDhg1h+1566SWNHj1a+/fvV//+/Z398fHx8nq9Hf3tAQA/IBH/TCoQCMjlcikxMTFs/+LFi5WcnKyRI0dqyZIlam5ubvccoVBIwWAwbAMAdH8dfiXVEcePH9f8+fM1ffp0JSQkOPsffvhhXXPNNUpKStJHH32kwsJC1dTU6Nlnn23zPEVFRVq4cGEkRwUAWMhljDHn/GSXS6tXr9bUqVNbHWtqalJubq4OHDig4uLisEj9r2XLlun+++9XQ0OD3G53q+OhUEihUMh5HAwGlZ6errGaolhXz3MdHwAQJc2mScVaq0AgcNo+ROSVVFNTk375y19q37592rx582kHkCS/36/m5mZ99dVXGjJkSKvjbre7zXgBALq3To/UqUDt2bNHW7ZsUXJy8hmfU1FRoZiYGKWkpHT2OACALqzDkWpoaFBVVZXzuLq6WhUVFUpKSlJaWpp+8YtfaNeuXVq3bp1Onjyp2tpaSVJSUpLi4uJUWlqqsrIyjRs3TvHx8SotLdW8efN011136ZJLLum8rwwA0OV1+DOp4uJijRs3rtX+GTNm6Omnn1ZGRkabz9uyZYvGjh2rXbt26aGHHtKXX36pUCikjIwM/epXv1JBQcFZv6UXDAbl8Xj4TAoAuqiz/UzqvG6ciBYiBQBd29lGip/dBwCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYC0iBQCwFpECAFiLSAEArNXhSJWUlGjy5Mny+XxyuVxas2ZN2PF77rlHLpcrbJs4cWLYmiNHjigvL08JCQlKTEzUzJkz1dDQcF5fCACg++lwpBobG5WZmamlS5e2u2bixImqqalxtrfeeivseF5enj777DNt2LBB69atU0lJiWbPnt3x6QEA3VpsR5+Qk5OjnJyc065xu93yer1tHvviiy+0fv167dixQ9dee60k6cUXX9SkSZP05z//WT6fr6MjAQC6qYh8JlVcXKyUlBQNGTJEDz74oA4fPuwcKy0tVWJiohMoScrOzlZMTIzKysraPF8oFFIwGAzbAADdX6dHauLEifr73/+uTZs26U9/+pO2bt2qnJwcnTx5UpJUW1urlJSUsOfExsYqKSlJtbW1bZ6zqKhIHo/H2dLT0zt7bACAhTr8dt+ZTJs2zfn18OHDNWLECA0ePFjFxcUaP378OZ2zsLBQBQUFzuNgMEioAOAHIOK3oA8aNEh9+/ZVVVWVJMnr9erQoUNha5qbm3XkyJF2P8dyu91KSEgI2wAA3V/EI3XgwAEdPnxYaWlpkqSsrCzV19ervLzcWbN582a1tLTI7/dHehwAQBfS4bf7GhoanFdFklRdXa2KigolJSUpKSlJCxcuVG5urrxer/bu3asnnnhCl19+uSZMmCBJuuqqqzRx4kTNmjVLr7zyipqamjRnzhxNmzaNO/sAAGE6/Epq586dGjlypEaOHClJKigo0MiRI/XUU0+pR48e2r17t2655RZdeeWVmjlzpkaNGqUPP/xQbrfbOcfKlSs1dOhQjR8/XpMmTdL111+vV199tfO+KgBAt+AyxphoD9FRwWBQHo9HYzVFsa6e0R4HANBBzaZJxVqrQCBw2vsM+Nl9AABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWkQKAGAtIgUAsBaRAgBYi0gBAKxFpAAA1iJSAABrESkAgLWIFADAWh2OVElJiSZPniyfzyeXy6U1a9aEHXe5XG1uS5YscdYMHDiw1fHFixef9xcDAOheOhypxsZGZWZmaunSpW0er6mpCduWLVsml8ul3NzcsHWLFi0KWzd37txz+woAAN1WbEefkJOTo5ycnHaPe73esMdr167VuHHjNGjQoLD98fHxrdYCAPDfIvqZVF1dnT744APNnDmz1bHFixcrOTlZI0eO1JIlS9Tc3NzueUKhkILBYNgGAOj+OvxKqiNef/11xcfH67bbbgvb//DDD+uaa65RUlKSPvroIxUWFqqmpkbPPvtsm+cpKirSwoULIzkqAMBCLmOMOecnu1xavXq1pk6d2ubxoUOH6sYbb9SLL7542vMsW7ZM999/vxoaGuR2u1sdD4VCCoVCzuNgMKj09HSN1RTFunqe6/gAgChpNk0q1loFAgElJCS0uy5ir6Q+/PBDVVZW6p133jnjWr/fr+bmZn311VcaMmRIq+Nut7vNeAEAureIfSb12muvadSoUcrMzDzj2oqKCsXExCglJSVS4wAAuqAOv5JqaGhQVVWV87i6uloVFRVKSkpS//79JX3/dtx7772nv/zlL62eX1paqrKyMo0bN07x8fEqLS3VvHnzdNddd+mSSy45jy8FANDddDhSO3fu1Lhx45zHBQUFkqQZM2ZoxYoVkqS3335bxhhNnz691fPdbrfefvttPf300wqFQsrIyNC8efOc8wAAcMp53TgRLcFgUB6PhxsnAKCLOtsbJ/jZfQAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALAWkQIAWItIAQCsRaQAANYiUgAAaxEpAIC1iBQAwFpECgBgLSIFALBWbLQHOBfGGElSs5okE+VhAAAd1qwmSf/5+7w9XTJSR48elSRt0/9FeRIAwPk4evSoPB5Pu8dd5kwZs1BLS4sqKyt19dVX6+uvv1ZCQkK0RzprwWBQ6enpzH0BddXZmfvCYu4Lyxijo0ePyufzKSam/U+euuQrqZiYGF166aWSpISEhC71B3MKc194XXV25r6wmPvCOd0rqFO4cQIAYC0iBQCwVpeNlNvt1oIFC+R2u6M9Socw94XXVWdn7guLue3UJW+cAAD8MHTZV1IAgO6PSAEArEWkAADWIlIAAGsRKQCAtbpspJYuXaqBAweqV69e8vv9+vjjj6M9kqOoqEjXXXed4uPjlZKSoqlTp6qysjJszdixY+VyucK2Bx54IEoT/8fTTz/daq6hQ4c6x48fP678/HwlJyfr4osvVm5ururq6qI48fcGDhzYam6Xy6X8/HxJ9lzvkpISTZ48WT6fTy6XS2vWrAk7bozRU089pbS0NPXu3VvZ2dnas2dP2JojR44oLy9PCQkJSkxM1MyZM9XQ0BC1uZuamjR//nwNHz5cF110kXw+n+6++24dPHgw7Bxt/RktXrw4onOfaXZJuueee1rNNXHixLA1tl1zSW1+v7tcLi1ZssRZE61r3pm6ZKTeeecdFRQUaMGCBdq1a5cyMzM1YcIEHTp0KNqjSZK2bt2q/Px8bd++XRs2bFBTU5NuuukmNTY2hq2bNWuWampqnO2ZZ56J0sThfvSjH4XNtW3bNufYvHnz9P777+u9997T1q1bdfDgQd12221RnPZ7O3bsCJt5w4YNkqTbb7/dWWPD9W5sbFRmZqaWLl3a5vFnnnlGL7zwgl555RWVlZXpoosu0oQJE3T8+HFnTV5enj777DNt2LBB69atU0lJiWbPnh21uY8dO6Zdu3bpySef1K5du7Rq1SpVVlbqlltuabV20aJFYX8Gc+fOjejcZ5r9lIkTJ4bN9dZbb4Udt+2aSwqbt6amRsuWLZPL5VJubm7Yumhc805luqDRo0eb/Px85/HJkyeNz+czRUVFUZyqfYcOHTKSzNatW519P//5z80jjzwSvaHasWDBApOZmdnmsfr6etOzZ0/z3nvvOfu++OILI8mUlpZeoAnPziOPPGIGDx5sWlpajDF2Xm9JZvXq1c7jlpYW4/V6zZIlS5x99fX1xu12m7feessYY8znn39uJJkdO3Y4a/7xj38Yl8tlvvnmm6jM3ZaPP/7YSDL79u1z9g0YMMA899xzkR3uDNqafcaMGWbKlCntPqerXPMpU6aYG264IWyfDdf8fHW5V1InTpxQeXm5srOznX0xMTHKzs5WaWlpFCdrXyAQkCQlJSWF7V+5cqX69u2rYcOGqbCwUMeOHYvGeK3s2bNHPp9PgwYNUl5envbv3y9JKi8vV1NTU9i1Hzp0qPr372/VtT9x4oTeeOMN3XvvvXK5XM5+W6/3KdXV1aqtrQ27vh6PR36/37m+paWlSkxM1LXXXuusyc7OVkxMjMrKyi74zO0JBAJyuVxKTEwM27948WIlJydr5MiRWrJkiZqbm6Mz4P8oLi5WSkqKhgwZogcffFCHDx92jnWFa15XV6cPPvhAM2fObHXM1mt+trrcT0H/9ttvdfLkSaWmpobtT01N1ZdffhmlqdrX0tKiRx99VD/96U81bNgwZ/+dd96pAQMGyOfzaffu3Zo/f74qKyu1atWqKE4r+f1+rVixQkOGDFFNTY0WLlyon/3sZ/r0009VW1uruLi4Vn/xpKamqra2NjoDt2HNmjWqr6/XPffc4+yz9Xr/t1PXsK3v7VPHamtrlZKSEnY8NjZWSUlJ1vwZHD9+XPPnz9f06dPDfir3ww8/rGuuuUZJSUn66KOPVFhYqJqaGj377LNRnPb7t/puu+02ZWRkaO/evfrd736nnJwclZaWqkePHl3imr/++uuKj49v9da7rde8I7pcpLqa/Px8ffrpp2Gf60gKez97+PDhSktL0/jx47V3714NHjz4Qo/pyMnJcX49YsQI+f1+DRgwQO+++6569+4dtbk64rXXXlNOTo58Pp+zz9br3d00NTXpl7/8pYwxevnll8OOFRQUOL8eMWKE4uLidP/996uoqCiqP3du2rRpzq+HDx+uESNGaPDgwSouLtb48eOjNldHLFu2THl5eerVq1fYfluveUd0ubf7+vbtqx49erS6o6yurk5erzdKU7Vtzpw5WrdunbZs2aLLLrvstGv9fr8kqaqq6kKMdtYSExN15ZVXqqqqSl6vVydOnFB9fX3YGpuu/b59+7Rx40bdd999p11n4/U+dQ1P973t9Xpb3SDU3NysI0eORP3P4FSg9u3bpw0bNpzx/23k9/vV3Nysr7766sIMeJYGDRqkvn37Ot8bNl9zSfrwww9VWVl5xu95yd5rfjpdLlJxcXEaNWqUNm3a5OxraWnRpk2blJWVFcXJ/sMYozlz5mj16tXavHmzMjIyzviciooKSVJaWlqEp+uYhoYG7d27V2lpaRo1apR69uwZdu0rKyu1f/9+a6798uXLlZKSoptvvvm062y83hkZGfJ6vWHXNxgMqqyszLm+WVlZqq+vV3l5ubNm8+bNamlpccIbDacCtWfPHm3cuFHJyclnfE5FRYViYmJavZUWbQcOHNDhw4ed7w1br/kpr732mkaNGqXMzMwzrrX1mp9WtO/cOBdvv/22cbvdZsWKFebzzz83s2fPNomJiaa2tjbaoxljjHnwwQeNx+MxxcXFpqamxtmOHTtmjDGmqqrKLFq0yOzcudNUV1ebtWvXmkGDBpkxY8ZEeXJjHnvsMVNcXGyqq6vNv/71L5OdnW369u1rDh06ZIwx5oEHHjD9+/c3mzdvNjt37jRZWVkmKysrylN/7+TJk6Z///5m/vz5Yfttut5Hjx41n3zyifnkk0+MJPPss8+aTz75xLkLbvHixSYxMdGsXbvW7N6920yZMsVkZGSY7777zjnHxIkTzciRI01ZWZnZtm2bueKKK8z06dOjNveJEyfMLbfcYi677DJTUVER9j0fCoWMMcZ89NFH5rnnnjMVFRVm79695o033jD9+vUzd999d0TnPtPsR48eNY8//rgpLS011dXVZuPGjeaaa64xV1xxhTl+/LhzDtuu+SmBQMD06dPHvPzyy62eH81r3pm6ZKSMMebFF180/fv3N3FxcWb06NFm+/bt0R7JIanNbfny5cYYY/bv32/GjBljkpKSjNvtNpdffrn5zW9+YwKBQHQHN8bccccdJi0tzcTFxZlLL73U3HHHHaaqqso5/t1335mHHnrIXHLJJaZPnz7m1ltvNTU1NVGc+D/++c9/GkmmsrIybL9N13vLli1tfm/MmDHDGPP9behPPvmkSU1NNW6324wfP77V13P48GEzffp0c/HFF5uEhATz61//2hw9ejRqc1dXV7f7Pb9lyxZjjDHl5eXG7/cbj8djevXqZa666irzxz/+MSwE0Zj92LFj5qabbjL9+vUzPXv2NAMGDDCzZs1q9R+8tl3zU/72t7+Z3r17m/r6+lbPj+Y170z8/6QAANbqcp9JAQB+OIgUAMBaRAoAYC0iBQCwFpECAFiLSAEArEWkAADWIlIAAGsRKQCAtYgUAMBaRAoAYK3/B8Kif1NpqfqBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preds[0]['pred_masks'][0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15cefb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "F.softmax(preds[0]['pred_logits'].unsqueeze(0), dim=-1)[:, :, :-1].max(-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b202c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = preds[0]['pred_boxes'][15]\n",
    "\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(-1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=-1)\n",
    "\n",
    "box_xyxy = box_cxcywh_to_xyxy(bb)  # num_queries, 4\n",
    "box_xyxy[0] = box_xyxy[0]*200     # x min\n",
    "box_xyxy[1] = box_xyxy[1]*200     # y min\n",
    "box_xyxy[2] = box_xyxy[2]*200     # x max\n",
    "box_xyxy[3] = box_xyxy[3]*200     # y max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ea18a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98.5221,  69.9092, 110.9640,  86.4210], device='cuda:0',\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_xyxy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask2former",
   "language": "python",
   "name": "mask2former"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
